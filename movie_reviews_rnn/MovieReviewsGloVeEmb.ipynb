{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ML DSL in Action</center></h1>\n",
    "\n",
    "Google Cloud Platform: \n",
    "1. Google Dataproc\n",
    "2. Google Cloud Storage\n",
    "3. Google AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.griddynamics.dsl.ml.mldsl as mldsl\n",
    "from com.griddynamics.dsl.ml.settings.profiles import PySparkJobProfile, Profile\n",
    "from com.griddynamics.dsl.ml.settings.description import Platform\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sequences from Original Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge."
     ]
    }
   ],
   "source": [
    "!head -n 20 dev/aclImdb/test/pos/0_10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer to Create Sequences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Tokenizer on ML Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary path: /home/jovyan/work/data/.mldsl/ml_text_tokenizer.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<com.griddynamics.dsl.ml.py_script.PyScript at 0x7f2f3ed848d0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%py_script_open -n ml_text_tokenizer.py -p demo/scripts -o dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = Platform.GCP\n",
    "profile = PySparkJobProfile(root_path='/home/jovyan/work/data/demo/scripts',\n",
    "                                  bucket='ai4ops',\n",
    "                                  project='gd-gcp-techlead-experiments',\n",
    "                                  cluster='ai4ops',\n",
    "                                  region='global',\n",
    "                                  ai_region='us-central1',\n",
    "                                  job_prefix='demo_job',\n",
    "                                  job_async=False,\n",
    "                           )\n",
    "profile.args={\"--train_pos_path\": \"gs://ai4ops/mldsl/data/aclImdb/train/pos\",\n",
    "              \"--train_neg_path\": \"gs://ai4ops/mldsl/data/aclImdb/train/neg\",\n",
    "              \"--test_pos_path\": \"gs://ai4ops/mldsl/data/aclImdb/test/pos\",\n",
    "              \"--test_neg_path\": \"gs://ai4ops/mldsl/data/aclImdb/test/neg\",\n",
    "              \"--max_seq\": \"500\",\n",
    "              \"--word_embeds\": \"gs://ai4ops/mldsl/data/glove.6B.50d.txt\"}\n",
    "Profile.set('CreateSequencesProfile', profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters string = <<<-n ml_text_tokenizer.py -p CreateSequencesProfile -pm 1 -o gs://ai4ops/mldsl/data>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/dataproc/jobs/demo_job_1586421552?project=gd-gcp-techlead-experiments&region=global\">demo_job_1586421552</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job with id demo_job_1586421552 was submitted to the cluster ai4ops\n",
      "Job STATUS was set to DONE at 2020-04-09 09:16:55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/storage/browser/ai4ops/mldsl/data/demo_job_1586421552?project=gd-gcp-techlead-experiments\">Output Data demo_job_1586421552</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "driver_control_files_uri": "gs://ai4ops/google-cloud-dataproc-metainfo/2d057403-a13f-40fa-b785-43cf3d7e2bc3/jobs/demo_job_1586421552/",
       "driver_output_resource_uri": "gs://ai4ops/google-cloud-dataproc-metainfo/2d057403-a13f-40fa-b785-43cf3d7e2bc3/jobs/demo_job_1586421552/driveroutput",
       "labels": {},
       "placement": {
        "cluster_name": "ai4ops"
       },
       "pyspark_job": {
        "archive_uris": [],
        "args": [
         "--output_path",
         "gs://ai4ops/mldsl/data/demo_job_1586421552",
         "--train_pos_path",
         "gs://ai4ops/mldsl/data/aclImdb/train/pos",
         "--train_neg_path",
         "gs://ai4ops/mldsl/data/aclImdb/train/neg",
         "--test_pos_path",
         "gs://ai4ops/mldsl/data/aclImdb/test/pos",
         "--test_neg_path",
         "gs://ai4ops/mldsl/data/aclImdb/test/neg",
         "--max_seq",
         "500",
         "--word_embeds",
         "gs://ai4ops/mldsl/data/glove.6B.50d.txt"
        ],
        "file_uris": [],
        "jar_file_uris": [],
        "logging_config": {
         "driver_log_levels": {}
        },
        "main_python_file_uri": "gs://ai4ops/jobs-root/demo_job_1586421552/ml_text_tokenizer.py",
        "properties": {},
        "python_file_uris": [
         "gs://ai4ops/jobs-root/demo_job_1586421552/ml_text_tokenizer.py"
        ]
       },
       "reference": {
        "job_id": "demo_job_1586421552",
        "project_id": "gd-gcp-techlead-experiments"
       },
       "scheduling": {
        "max_failures_per_hour": 0
       },
       "start_time": "2020-04-09T09:16:55.000000",
       "status": "DONE",
       "yarn_applications": [
        {
         "name": "word_tokenizer",
         "progress": 1,
         "state": "FINISHED",
         "trackingUrl": "http://ai4ops-m:8088/proxy/application_1570197709805_0236/"
        }
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%py_data -n ml_text_tokenizer.py -p CreateSequencesProfile -pm $platform -o gs://ai4ops/mldsl/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use job_demo_job_1586421552 instance to browse job properties.\n",
    "#job_demo_job_1586421552 = job_tracker['demo_job_1586421552']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading logs of dataproc job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"gd-gcp-techlead-experiments\"\n",
    "\n",
    "filters = \"\"\"resource.type:cloud_dataproc_cluster\n",
    "AND timestamp>2020-02-16\n",
    "AND resource.labels.cluster_name:ai4ops \n",
    "AND jsonPayload.application:application_1570197709805_0110\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%logging -p $project_id -f $filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model to Predict Positive or Negative Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Additional Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence is set to 200\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                10624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 20,010,740\n",
      "Trainable params: 10,690\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 23s 906us/sample - loss: 0.7030 - acc: 0.5114\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.6859 - acc: 0.5406\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 22s 884us/sample - loss: 0.6815 - acc: 0.5489\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 22s 888us/sample - loss: 0.6799 - acc: 0.5533\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.6608 - acc: 0.5915\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 22s 891us/sample - loss: 0.5942 - acc: 0.7172\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 22s 884us/sample - loss: 0.5762 - acc: 0.7370\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.7012 - acc: 0.5140\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 22s 884us/sample - loss: 0.6915 - acc: 0.5148\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 22s 884us/sample - loss: 0.6847 - acc: 0.5345\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 22s 880us/sample - loss: 0.6708 - acc: 0.5723\n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 22s 884us/sample - loss: 0.6274 - acc: 0.6644\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 22s 894us/sample - loss: 0.5561 - acc: 0.7432\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.5146 - acc: 0.7745\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 22s 889us/sample - loss: 0.4904 - acc: 0.7882\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 22s 883us/sample - loss: 0.4729 - acc: 0.7918\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 22s 887us/sample - loss: 0.4677 - acc: 0.7975\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.4458 - acc: 0.8069\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 22s 883us/sample - loss: 0.4438 - acc: 0.8084\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 22s 886us/sample - loss: 0.4407 - acc: 0.8078\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 22s 881us/sample - loss: 0.4199 - acc: 0.8172\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 22s 882us/sample - loss: 0.4095 - acc: 0.8196\n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 22s 879us/sample - loss: 0.4136 - acc: 0.8183\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 22s 886us/sample - loss: 0.4074 - acc: 0.8262\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 22s 883us/sample - loss: 0.3963 - acc: 0.8278\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 22s 887us/sample - loss: 0.3863 - acc: 0.8311\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 22s 890us/sample - loss: 0.4462 - acc: 0.8077\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 22s 885us/sample - loss: 0.4395 - acc: 0.8066\n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 22s 879us/sample - loss: 0.4223 - acc: 0.8183\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 22s 883us/sample - loss: 0.3946 - acc: 0.8283\n",
      "Saving the model as SavedModel is not supported in TensorFlow 1.Xgraph mode. Please enable eager execution or use the \"h5\" save format.\n",
      "Temporary path: /home/jovyan/work/data/.mldsl/mr_model.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<com.griddynamics.dsl.ml.py_script.PyScript at 0x7f2f3fd444e0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%py_script -e -n mr_model.py -p demo/model/words/trainer -o ./dev/models --epochs 30 --train_path gs://ai4ops/mldsl/data/demo_job_1586421552/train --word_embeds gs://ai4ops/mldsl/data/demo_job_1586421552/words --seq_len 200\n",
    "#!/usr/bin/python\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.callbacks import Callback\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "    from tensorflow.keras.backend import set_session\n",
    "    tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "    from uuid import uuid4\n",
    "    import argparse\n",
    "    import matplotlib\n",
    "    if matplotlib.get_backend() in ['TkAgg', 'TkCairo']:\n",
    "        matplotlib.use('agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "class MetricCallback(Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('acc'))\n",
    "\n",
    "\n",
    "def read_glove_vectors(glove_file):\n",
    "    files = file_io.get_matching_files('{}/part*'.format(glove_file))\n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            word_to_vec_map = {}\n",
    "            words_to_index = {}\n",
    "        fl = f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            word_to_vec_map[line[0]] = np.array(line[1].split(','), dtype=np.float64)\n",
    "            words_to_index[line[0]] = int(line[2])\n",
    "    return words_to_index, word_to_vec_map\n",
    "\n",
    "\n",
    "def read_csv(path):\n",
    "    files = file_io.get_matching_files('{}/part*'.format(path))\n",
    "    pdf = []\n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            df = pd.read_csv(f)\n",
    "            if df is not None and len(df) != 0:\n",
    "                pdf.append(df)\n",
    "    if len(pdf) == 0:\n",
    "        return None\n",
    "    return pd.concat(pdf, axis=0, ignore_index=True).reset_index()\n",
    "\n",
    "\n",
    "def pretrained_embed_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    embedding_layer = Embedding(input_dim=vocab_len, trainable=False, output_dim=emb_dim)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def define_model(input_shape, word_to_vec_map, word_to_index, rnn_units, dropout=0.5):\n",
    "    sentence_indices = Input(input_shape, dtype=\"int32\")\n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer = pretrained_embed_layer(word_to_vec_map, word_to_index)\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    X = LSTM(units=rnn_units, return_sequences=False)(embeddings)\n",
    "    # Add dropout with a probability \n",
    "    X = Dropout(dropout)(X)\n",
    "    # Propagate X through a Dense layer\n",
    "    X = Dense(2)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation(\"softmax\")(X)\n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C=2):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def prepare_dataset(path, N, word_to_index):\n",
    "    data = read_csv(path)\n",
    "    data.dropna(inplace=True)\n",
    "    data['int_seq'] = data['int_seq'].apply(lambda x: [int(i) for i in x.split(',')])\n",
    "    l = data['int_seq'].apply(lambda x: len(x))\n",
    "    print(\"Max sequence is set to {}\".format(N))\n",
    "    data['int_seq'] = data['int_seq'].apply(lambda x: (x + [word_to_index[\"unk\"]] * N)[:N])\n",
    "    ds_x = np.asarray(list(data[\"int_seq\"]))\n",
    "    ds_y = data[\"class\"].values\n",
    "    return ds_x, ds_y, l\n",
    "\n",
    "\n",
    "def plot_metrics(callback, dir_to_save):\n",
    "    f, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "    plt.style.use('seaborn')\n",
    "    plt.rcParams['axes.titlesize'] = 16\n",
    "    sns.lineplot(x=range(len(callback.losses)), y=callback.losses, ax=axes[0])\n",
    "    axes[0].title.set_text(\"Loss\")\n",
    "    sns.lineplot(x=range(len(callback.accuracies)), y=callback.accuracies, ax=axes[1])\n",
    "    axes[1].title.set_text(\"Accuracy\")\n",
    "    plt.tight_layout(.5)\n",
    "    plt.savefig('{}'.format(dir_to_save))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_path', type=str, help=\"Train files path\")\n",
    "    parser.add_argument('--output_path', type=str, help=\"Models output path\")\n",
    "    parser.add_argument('--word_embeds', type=str, help=\"Models output path\")\n",
    "    parser.add_argument('--seq_len', type=int, help=\"Length of input sequence\")\n",
    "    parser.add_argument('--epochs', type=int, help=\"Number of epochs\")\n",
    "    args, d = parser.parse_known_args()\n",
    "\n",
    "    word_to_index, word_to_vec_map = read_glove_vectors(args.word_embeds)\n",
    "    N = args.seq_len\n",
    "    train_x, train_y, l = prepare_dataset(args.train_path, N, word_to_index)\n",
    "    train_y = convert_to_one_hot(train_y, C=2)\n",
    "    NUM_EPOCS = args.epochs\n",
    "    RNN_STATE_DIM = 32\n",
    "    LEARNING_RATE = 0.01\n",
    "\n",
    "    config_proto = tf.ConfigProto()\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    session = tf.Session(config=config_proto)\n",
    "    set_session(session)\n",
    "\n",
    "    model = define_model((N, ), word_to_vec_map, word_to_index, RNN_STATE_DIM)\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE), metrics=['accuracy'])\n",
    "    # fit model\n",
    "    metrics = MetricCallback()\n",
    "    a = model.fit(train_x, train_y, batch_size=1024, epochs=NUM_EPOCS, callbacks=[metrics], shuffle=True)\n",
    "\n",
    "    # save the model to file\n",
    "    local_dir = uuid4().hex\n",
    "    file_io.recursive_create_dir(local_dir)\n",
    "    local_path = '{}'.format(local_dir)\n",
    "    model.save(local_path, save_format='tf')\n",
    "    local_path_chart = '{}/metrics.png'.format(local_dir)\n",
    "    plot_metrics(metrics, local_path_chart)\n",
    "    \n",
    "    remote_dir = args.output_path\n",
    "    remote_path = '{}/saved_model.h5'.format(remote_dir)\n",
    "    remote_path_chart = '{}/metrics.png'.format(remote_dir)\n",
    "    \n",
    "    if not remote_dir.startswith('gs://'):\n",
    "        file_io.recursive_create_dir(remote_dir)\n",
    "    file_io.copy(local_path, remote_path)\n",
    "    file_io.copy(local_path_chart, remote_path_chart)\n",
    "    file_io.delete_recursively(local_dir)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence is set to 200\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "df_x, df_y, l = prepare_dataset('gs://ai4ops/mldsl/data/demo_job_1586421552/test', 200, word_to_index)\n",
    "\n",
    "ints = np.random.choice(len(df_y), 200)\n",
    "\n",
    "test_x = df_x[ints]\n",
    "test_y = df_y[ints]\n",
    "test = test_x.tolist()\n",
    "\n",
    "dense=model.predict(test_x)\n",
    "dense=(dense[:,0]<dense[:,1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(test_y, dense)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "classes=['Negative', 'Positive']\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',xticklabels=classes, yticklabels=classes, cmap=plt.cm.BuGn)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7938144329896907,\n",
       "  'recall': 0.875,\n",
       "  'f1-score': 0.8324324324324325,\n",
       "  'support': 88},\n",
       " '1': {'precision': 0.8932038834951457,\n",
       "  'recall': 0.8214285714285714,\n",
       "  'f1-score': 0.8558139534883721,\n",
       "  'support': 112},\n",
       " 'accuracy': 0.845,\n",
       " 'macro avg': {'precision': 0.8435091582424181,\n",
       "  'recall': 0.8482142857142857,\n",
       "  'f1-score': 0.8441231929604023,\n",
       "  'support': 200},\n",
       " 'weighted avg': {'precision': 0.8494725252727454,\n",
       "  'recall': 0.845,\n",
       "  'f1-score': 0.8455260842237586,\n",
       "  'support': 200}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(test_y, dense,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
